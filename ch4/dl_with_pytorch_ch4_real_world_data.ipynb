{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Real world data\n",
        "In this notebook we will learn how to handle different types of data: 2D images, 3D images, tabular data and text."
      ],
      "metadata": {
        "id": "Hd7cVmjWZ4nG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2D images"
      ],
      "metadata": {
        "id": "t2G1yVX5aLMl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpyv7yObc3fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba7f2a2-5192-46d1-c617-ede3c6ff5afb"
      },
      "source": [
        "!git clone https://github.com/deep-learning-with-pytorch/dlwpt-code.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dlwpt-code'...\n",
            "remote: Enumerating objects: 703, done.\u001b[K\n",
            "remote: Total 703 (delta 0), reused 0 (delta 0), pack-reused 703\u001b[K\n",
            "Receiving objects: 100% (703/703), 176.00 MiB | 21.27 MiB/s, done.\n",
            "Resolving deltas: 100% (309/309), done.\n",
            "Checking out files: 100% (228/228), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFYFA5Y6dfu1",
        "outputId": "01c6d974-3fbc-4054-be91-bb14355997d4"
      },
      "source": [
        "cd /content/dlwpt-code/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dlwpt-code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2YOpuQOc0lG"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "torch.set_printoptions(edgeitems=2, threshold=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5PBgyqdc0lL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a429c49-8fc6-4c05-f873-5fa4bea167f4"
      },
      "source": [
        "import imageio\n",
        "\n",
        "img_arr = imageio.imread('data/p1ch4/image-dog/bobby.jpg')\n",
        "img_arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(720, 1280, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An image is represented by several Python packages as a three dimensional NumPy array, in this case as [height, width, channels]. A PyTorch tensor uses the 1st dimension for the channels and the other two as height and width respectively [channles, height, width]. So if we want to work with an image we have to change the layout, the metadata of the image, by permuting the 1st dimension of the image with the 3rd. "
      ],
      "metadata": {
        "id": "h9352ZbfIUVJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlxCorRQc0lN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b9a6a8-1bce-429f-ef3c-408d34c73c1b"
      },
      "source": [
        "img = torch.from_numpy(img_arr)\n",
        "out = img.permute(2, 0, 1)\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 720, 1280])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to create a batch of  three RGB images. In order to do so we create an empty four dimensional tensor [batch-size, channels, height, width] that we will fill with images"
      ],
      "metadata": {
        "id": "arlgBisuNeJQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0nFguVbc0lN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd52d935-f07f-4252-a9e6-f896e7ff42fd"
      },
      "source": [
        "batch_size = 3\n",
        "channels = 3\n",
        "height = 256\n",
        "width = 256\n",
        "batch = torch.zeros(batch_size, channels, height, width, dtype=torch.uint8)\n",
        "batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vFX7Ez04c0lO"
      },
      "source": [
        "import os\n",
        "\n",
        "data_dir = 'data/p1ch4/image-cats/'\n",
        "filenames = [name for name in os.listdir(data_dir)\n",
        "             if os.path.splitext(name)[-1] == '.png']\n",
        "for i, filename in enumerate(filenames):\n",
        "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
        "    img_t = torch.from_numpy(img_arr)\n",
        "    img_t = img_t.permute(2, 0, 1)\n",
        "    img_t = img_t[:3] # <1>\n",
        "    batch[i] = img_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORT6SGSzc0lO"
      },
      "source": [
        "batch = batch.float()\n",
        "batch /= 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNPyMl1lc0lP"
      },
      "source": [
        "n_channels = batch.shape[1]\n",
        "for c in range(n_channels):\n",
        "    mean = torch.mean(batch[:, c])\n",
        "    std = torch.std(batch[:, c])\n",
        "    batch[:, c] = (batch[:, c] - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3D images\n",
        "3D images are used in the medical domain, such as for Computed Tomography (CT) scan and Magnetic resonance Imaging (MRI), where a scan is represented as a batch of images where the batch index represents the length of the body and each image is a slice of the body. They are also used in Geophysics where one dimension can be the height and the other two are used to represent a surface or layer. CT scans use single band images, that is only one channel. A complete dataset can be represented as a 5 dimensional tensor:   \n",
        "[number of batches, channels, depth, height, width]  "
      ],
      "metadata": {
        "id": "g-X4ZIasaPEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We open 99 DICOM files and put them into an array"
      ],
      "metadata": {
        "id": "ZwZyZbT0vK9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data/p1ch4/volumetric-dicom/LUNG-IMAGES/'\n",
        "vol_arr = imageio.volread(data_dir, 'DICOM')\n",
        "vol_arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xawk38pZmyOt",
        "outputId": "d2c8e9f3-8f4d-4ef5-b604-2c728d01f8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading DICOM (examining files): 1/99 files (1.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b99/99 files (100.0%)\n",
            "  Found 1 correct series.\n",
            "Reading DICOM (loading data): 45/99  (45.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b99/99  (100.0%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to transform the array of integers into a PyTorch tensor of floats by adding a dimension so that we will have one channel, of depth=99 with images of height=512 and width=512"
      ],
      "metadata": {
        "id": "dv4tnsQRvbGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vol = torch.from_numpy(vol_arr).float()\n",
        "vol = torch.unsqueeze(vol, 0)\n",
        "vol.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_IA6ee0ur5l",
        "outputId": "413a0034-b922-409e-8201-8e26f3133327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 99, 512, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tabular data\n",
        "We open a tabular dataset that contains values for several characteristics used to assess the quality of wines. We import the data into a NumPy array and then into a Pytorch tensor."
      ],
      "metadata": {
        "id": "ixtDMHMwwvA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine_path = 'data/p1ch4/tabular-wine/winequality-white.csv'\n",
        "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
        "wineq_numpy.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReXeOPdYvSQN",
        "outputId": "3fce3ae3-74e8-4103-f07a-49adcaf83f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4898, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wineq = torch.from_numpy(wineq_numpy)\n",
        "wineq.shape, wineq.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkF3qK9dKE0-",
        "outputId": "75eded90-2287-4d95-82c3-0445aee88f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898, 12]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We print the column names"
      ],
      "metadata": {
        "id": "phQtwjHHHVfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
        "col_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-slJ0NWGJZw",
        "outputId": "23fe1153-51a9-4c04-bf70-b56bd7e7b6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fixed acidity',\n",
              " 'volatile acidity',\n",
              " 'citric acid',\n",
              " 'residual sugar',\n",
              " 'chlorides',\n",
              " 'free sulfur dioxide',\n",
              " 'total sulfur dioxide',\n",
              " 'density',\n",
              " 'pH',\n",
              " 'sulphates',\n",
              " 'alcohol',\n",
              " 'quality']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to see what relation there is between the sulphates content and the quality of wines. That is a regression task. We separate the data from the labels that in this case is the value of the 'quality' column."
      ],
      "metadata": {
        "id": "mXYXoG3NJB3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = wineq[:, :-1]\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOAg-FC0Gws2",
        "outputId": "2dd8ebe4-66d3-43c4-9f01-395f582ea28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4898, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = wineq[:, -1].long()\n",
        "label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMwzz6wUJ5Vb",
        "outputId": "edc60c50-e00e-4db6-e9da-81d30c2b380d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4898])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous values\n",
        "The label, that is the quality of the wine, is represented by an integer value between 3 and 9. This way of representing the quality makes sense since we assume a wine with quality=9 is 3 times better than a wine with quality=3"
      ],
      "metadata": {
        "id": "rdIvojK4NUeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM9B77AbNFoG",
        "outputId": "cc3ba7a3-3ab1-4805-8d52-31365f4ded64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugnK6tEcNQes",
        "outputId": "24c32fc6-8e3c-4042-bb8a-0bcaa217ff66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical values\n",
        "In other case the label might indicate only that the item belongs to a certain class without any further meaning. In this case we might use the one-hot encoding mapping a value to a vector with all element 0 but only one set to 1 that represents its category."
      ],
      "metadata": {
        "id": "JIMm8B3pPTaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_onehot = torch.zeros(label.shape[0], 10)\n",
        "label_onehot.scatter_(1, label.unsqueeze(1), 1.0)\n",
        "label_onehot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mUjpTJhNR_0",
        "outputId": "6dfeaec4-3bfa-445e-9074-fcf007b3bb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the mean and the variance for each column of our data"
      ],
      "metadata": {
        "id": "siypm4IlSysK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_mean = data.mean(dim=0)\n",
        "data_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "508heYPCOD8z",
        "outputId": "554097c6-89d8-4cf3-c321-01e1401e9031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
              "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_var = data.var(dim=0)\n",
        "data_var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldBqyXqESYyD",
        "outputId": "292e8c1f-531c-4205-d662-879b4b622ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
              "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can normalize the data by subtracting the mean and dividing by the standard deviation."
      ],
      "metadata": {
        "id": "JpE1GuvuTRkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
        "data_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF1YapxwSnPK",
        "outputId": "3b28b2e9-9a4b-440f-939e-41808496e88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.7208e-01, -8.1761e-02,  ..., -3.4915e-01, -1.3930e+00],\n",
              "        [-6.5743e-01,  2.1587e-01,  ...,  1.3422e-03, -8.2419e-01],\n",
              "        ...,\n",
              "        [-1.6054e+00,  1.1666e-01,  ..., -9.6251e-01,  1.8574e+00],\n",
              "        [-1.0129e+00, -6.7703e-01,  ..., -1.4882e+00,  1.0448e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the number of wine with quality equal or less than 3. We can see that there are only 20 wines out of 4898 that have a such a low quality."
      ],
      "metadata": {
        "id": "jINy9FELVHhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_indexes = label <= 3\n",
        "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAnVNfWVTwFq",
        "outputId": "33f0b190-d982-4565-8e65-2fc1ec1098ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(20))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2k15I6AUDEr",
        "outputId": "f3b266b9-2850-4e58-adbf-1b59d920444a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([], size=(0, 4898), dtype=torch.bool)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can filter these wines from the data tensor using the bad_indexes"
      ],
      "metadata": {
        "id": "ULT28mAkV48m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_data = data[bad_indexes]\n",
        "bad_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gxiNh6nUINj",
        "outputId": "0fc10009-fb6d-411c-89e8-0bf069a8cddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It might be interesting to see what attributes values are linked to such a low quality for each of these 20 wines. We can divide the wines in three categories."
      ],
      "metadata": {
        "id": "t6XuULXVWlOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_data = data[label <= 3]\n",
        "mid_data = data[(label > 3) & (label < 7)]\n",
        "good_data = data[label >= 7]"
      ],
      "metadata": {
        "id": "eKxdtWMqVouU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_mean = torch.mean(bad_data, dim=0)\n",
        "mid_mean = torch.mean(mid_data, dim=0)\n",
        "good_mean = torch.mean(good_data, dim=0)"
      ],
      "metadata": {
        "id": "-EtqVzhVWUdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can print the mean values for each of the 11 attributes in the three categories. We can see that there is an inverse correlation between the sulfur dioxied and the quality: a good wine contains less sulfur than a medium wine, and a medium wine contains less sulfur than a bad one. "
      ],
      "metadata": {
        "id": "6Ov5RdMhYXpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
        "  print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwdq4G4MXnpL",
        "outputId": "434eae11-eb0e-4779-e9b4-3c0131b9b419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0 fixed acidity          7.60   6.89   6.73\n",
            " 1 volatile acidity       0.33   0.28   0.27\n",
            " 2 citric acid            0.34   0.34   0.33\n",
            " 3 residual sugar         6.39   6.71   5.26\n",
            " 4 chlorides              0.05   0.05   0.04\n",
            " 5 free sulfur dioxide   53.33  35.42  34.55\n",
            " 6 total sulfur dioxide 170.60 141.83 125.25\n",
            " 7 density                0.99   0.99   0.99\n",
            " 8 pH                     3.19   3.18   3.22\n",
            " 9 sulphates              0.47   0.49   0.50\n",
            "10 alcohol               10.34  10.26  11.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time series"
      ],
      "metadata": {
        "id": "lDtbmnfqaHpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_path = 'data/p1ch4/bike-sharing-dataset/hour-fixed.csv'\n",
        "bikes_numpy = np.loadtxt(bike_path, dtype=np.float32, delimiter=',', skiprows=1, converters={1: lambda x: float(x[8:10])})\n",
        "bikes_numpy[0]"
      ],
      "metadata": {
        "id": "-TefRiFhXuu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886554d9-ac3b-43b8-bf50-d367f3cd300f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.    ,  1.    ,  1.    ,  0.    ,  1.    ,  0.    ,  0.    ,\n",
              "        6.    ,  0.    ,  1.    ,  0.24  ,  0.2879,  0.81  ,  0.    ,\n",
              "        3.    , 13.    , 16.    ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bikes = torch.from_numpy(bikes_numpy)\n",
        "bikes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlDxgumqUWIQ",
        "outputId": "edd6a820-c4fe-47e8-e13c-272894cb65be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 1.0000e+00,  ..., 1.3000e+01, 1.6000e+01],\n",
              "        [2.0000e+00, 1.0000e+00,  ..., 3.2000e+01, 4.0000e+01],\n",
              "        ...,\n",
              "        [1.7378e+04, 3.1000e+01,  ..., 4.8000e+01, 6.1000e+01],\n",
              "        [1.7379e+04, 3.1000e+01,  ..., 3.7000e+01, 4.9000e+01]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to have a look at the attributes "
      ],
      "metadata": {
        "id": "I8sqXrclYCun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_list = next(csv.reader(open(bike_path), delimiter=','))\n",
        "col_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXoEOiN9UVjx",
        "outputId": "642168c7-af52-434d-a4e7-8b491eea1247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['instant',\n",
              " 'dteday',\n",
              " 'season',\n",
              " 'yr',\n",
              " 'mnth',\n",
              " 'hr',\n",
              " 'holiday',\n",
              " 'weekday',\n",
              " 'workingday',\n",
              " 'weathersit',\n",
              " 'temp',\n",
              " 'atemp',\n",
              " 'hum',\n",
              " 'windspeed',\n",
              " 'casual',\n",
              " 'registered',\n",
              " 'cnt']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bikes.shape, bikes.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Y2SGVqUtMo",
        "outputId": "158598a1-829a-4d54-aa86-1dee13e37626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([17520, 17]), (17, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to add two dimensions to separate the days and the times of bike sharing, so one dimension will be for the day (730 days), one for the hour (24 hours), and another for the attributes (17 attributes). We will create a new view of the data. A new view creates new metadata of the same data so that the same data will be interpreted in a different way. "
      ],
      "metadata": {
        "id": "mawz7blnXmnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
        "daily_bikes.shape, daily_bikes.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhhXaIeVXNr4",
        "outputId": "38d990af-dd6e-4f4b-fc0b-532e787637f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([730, 24, 17]), (408, 17, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each day is represented by a sequence of 24 hourly attributes. The dataset contains N=17520 / 24 = 730 sequences, each sequence has C=17 channels (attributes) and L=24 ordered data points. We have to transpose the dataset to be NxCxL"
      ],
      "metadata": {
        "id": "q0ww9Oz7bfV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_bikes = daily_bikes.transpose(1, 2)\n",
        "daily_bikes.shape, daily_bikes.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhuGAc90Ye1x",
        "outputId": "98ed00be-8f55-40fa-dae1-ad3d92ae9a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([730, 17, 24]), (408, 1, 17))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_day = bikes[:24].long()\n",
        "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
        "first_day[:,9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHvUpeEGbQkA",
        "outputId": "16d44bfb-0d0f-4367-bb53-2292695c9835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weather_onehot.scatter_(dim=1, index=first_day[:,9].unsqueeze(1).long() - 1, value=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULS2RAXIc17b",
        "outputId": "1c9c0106-4f0e-4e9e-ea3a-8e2ee2921671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQDdtvHOdXxR",
        "outputId": "c4c07949-82cc-44bf-c8a2-e4d3ed29fa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
              "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
              "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])"
      ],
      "metadata": {
        "id": "jTn89I0Odg6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_weather_onehot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Now1IxAWe0nY",
        "outputId": "1171a97d-e3bd-41c3-96d7-a789753f411c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([730, 4, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_weather_onehot.scatter_(1, daily_bikes[:,9,:].long().unsqueeze(1) - 1, 1.0)\n",
        "daily_weather_onehot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvgq4vWOe3ml",
        "outputId": "b64b439f-35d5-4e32-f302-722cb80fdf15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([730, 4, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)"
      ],
      "metadata": {
        "id": "TJ6sOmO_fEcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_bikes[:, 9, :] = (daily_bikes[:, 9, :] - 1.0) / 3.0"
      ],
      "metadata": {
        "id": "jA2P8lPqfIt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text\n",
        "In this section we will see how to represent text in a way that is suitable to be processed by a neural network for tasks such as machine translation and other Natural Language Processing (NLP) tasks. Text can be processed at the characters level or at the words level. In both cases they can be represented as vectors in a way similar to the one-hot encoding.Characters are represented as a sequence of bits in different encoding schemes. The simplest is ASCII that uses 7 bits to represent a character. Each character can be thought as a vector in a 7 dimensional space."
      ],
      "metadata": {
        "id": "8sab0jJ4qd01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data/p1ch4/jane-austen/1342-0.txt', encoding='utf8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "e9rY6-5cfTPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = text.split('\\n')\n",
        "len(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo9cm56lB9D-",
        "outputId": "ff39dbac-ed2d-4dde-c444-9b56f20a7a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13428"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line = lines[200]\n",
        "line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "E_NWAPqqNpa8",
        "outputId": "d54e78d7-155b-4a5f-def1-d09704c30e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U3LTDapwEwfW",
        "outputId": "21d24f3b-3d48-4d54-ba87-e339e7244423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding of characters\n",
        "We create a 2D tensor from the characters in the line. For each character (row) we will write a '1' in the column that matches the character encoding "
      ],
      "metadata": {
        "id": "V_lhJ00KFHYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letter_t = torch.zeros(len(line), 128)\n",
        "letter_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcj5MsY_E-YW",
        "outputId": "6ddc85a2-ad96-4ebf-f9c3-693ac6c3bcf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([70, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We parse the line to change all characters to lower case"
      ],
      "metadata": {
        "id": "IirOwfrKIZiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, letter in enumerate(line.lower().strip()):\n",
        "  letter_index = ord(letter) if ord(letter) < 128 else 0\n",
        "  letter_t[i][letter_index] = 1"
      ],
      "metadata": {
        "id": "uAVcj_x9E__N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that row[1] represents 1st letter \"I\" changed to lower case \"i\" (ASCII code 105). It represents the one-hot encoding of character \"i\" in ASCII. The tensor represents the first line of the text so that the text can be represented as a batch of tensors."
      ],
      "metadata": {
        "id": "68b3IIZjJFTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nonzero(letter_t[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdxvWk4iFvbv",
        "outputId": "6ed6d745-ec6b-4d26-ddeb-aca01e6dd404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[105]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding of words\n",
        "We can use words in a vocabulary as vector basis. A vocabulary has usually thousands of words so the one-hot encoding uses vectors that are very long and a line is represented by a big and sparse tensor. We apply the same transformation as before to change the characters in words to be lower case and without punctuation"
      ],
      "metadata": {
        "id": "brIcEgEHK4wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_words(input_str):\n",
        "  punctuation = '.,;:\"!?”“_-'\n",
        "  word_list = input_str.lower().replace('\\n',' ').split()\n",
        "  word_list = [word.strip(punctuation) for word in word_list]\n",
        "  return word_list"
      ],
      "metadata": {
        "id": "D6ydWKm9GzFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_line = clean_words(line)\n",
        "line, words_in_line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0KX5lpKMa1Q",
        "outputId": "b3a42aa2-1eea-46a3-a141-3c2555c61318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
              " ['impossible',\n",
              "  'mr',\n",
              "  'bennet',\n",
              "  'impossible',\n",
              "  'when',\n",
              "  'i',\n",
              "  'am',\n",
              "  'not',\n",
              "  'acquainted',\n",
              "  'with',\n",
              "  'him'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We build a dictionary of the words in the text, the keys are words and the values are numbers."
      ],
      "metadata": {
        "id": "kFJ7-6i-OABN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = sorted(set(clean_words(text)))\n",
        "word2index_dict = {word: i for (i, word) in enumerate(word_list)}"
      ],
      "metadata": {
        "id": "RPOVXrCuMeeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dictionary has 7261 words. This means that we will need vectors of the same length to represent each word"
      ],
      "metadata": {
        "id": "1pilpi1sORNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2index_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-Fm9_0eMqwy",
        "outputId": "3d7d578d-1cff-4688-ea8f-37126143bb21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7261"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the value associated to each word"
      ],
      "metadata": {
        "id": "ARBsd6JYOZrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2index_dict['impossible']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF54__MAOWnb",
        "outputId": "3f6179a3-b022-4748-f678-6abd0dea3e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3394"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now represent each line as a tensor"
      ],
      "metadata": {
        "id": "ROmC3tvxPFMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
        "\n",
        "for i, word in enumerate(words_in_line):\n",
        "  word_index = word2index_dict[word]\n",
        "  word_t[i][word_index] = 1\n",
        "  print('{:2} {:4} {}'.format(i, word_index, word))\n",
        "\n",
        "print(word_t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dGgphlkOXrL",
        "outputId": "6f8b53fc-227e-4eeb-85c7-4848a83eb86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0 3394 impossible\n",
            " 1 4305 mr\n",
            " 2  813 bennet\n",
            " 3 3394 impossible\n",
            " 4 7078 when\n",
            " 5 3315 i\n",
            " 6  415 am\n",
            " 7 4436 not\n",
            " 8  239 acquainted\n",
            " 9 7148 with\n",
            "10 3215 him\n",
            "torch.Size([11, 7261])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text embeddings\n",
        "Even using grammar rules to reduce the number of terms that can be found in a text we will end up with verctors with thousands of zeros and just a single one. We can improve the situation by using float numbers to represent words. This technique is called embeddings. The idea is to represent words that are related with vectors in a small space, let's say 100 dimensions, that are closer than to other words that do not have any relationships with them. For example a sea and a lake are related by the fact that it's water, a german sheperd and a collie are related by the fact that they're dogs and so on. We do not want to build the embeddings by hand. Embeddings can be created by a neural network to cluster words that are related in some way. We will not address embeddings in this book. Embeddings are an alternative to one-hot encodings for categorical data.\n"
      ],
      "metadata": {
        "id": "0E6TsaVRP8sN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OyQLDgZRO9kW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}