{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3af65cb",
   "metadata": {},
   "source": [
    "# Character-level language model\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/luigiselmi/machine_learning_notes/blob/main/pml3/char_level_language_model.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "We want to build a character-level language model based of a RNN that can generate new text with the same style of a text that has been used for training. We download the book \"The Mysterious Island\" by Julius Verne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c3c52e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!wget 'https://www.gutenberg.org/files/1268/1268-0.txt' -P data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83692f",
   "metadata": {},
   "source": [
    "We use the text from the title and count the total number of characters and the number of unique characters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdb8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1130711\n",
      "Unique Characters: 85\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Reading and processing text\n",
    "with open('data/1268-0.txt', 'r', encoding=\"utf8\") as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d29e0",
   "metadata": {},
   "source": [
    "We encode the characters in the text as integers. The integer values can be decoded into characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e19e2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char2int['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937ef1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
       "       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_array = np.array(chars_sorted)\n",
    "char_array[29:81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87bd789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1130711,)\n",
      "THE MYSTERIOUS       == Encoding ==>  [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n",
      "[37 47 40 29 42 32]  == Reverse  ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "\n",
    "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b14a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 -> T\n",
      "36 -> H\n",
      "33 -> E\n",
      "1 ->  \n",
      "41 -> M\n"
     ]
    }
   ],
   "source": [
    "for ex in text_encoded[:5]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7efaa4",
   "metadata": {},
   "source": [
    "## Character prediction as a multiclass classification task\n",
    "The text generation task, where a sequence of characters are used to infer the next one, can be thought as a multiclass classification task where an incomplete text is mapped (i.e. classified) to one of the characters in our alphabet of unique characters. We create the training set using sequences of characters from the text and as label the character immediately after the last character. We choose the lenght of the sequences to be 41, 40 for the sequences and 1 for the label, that is the character after each sequence. Our model should allows us to create new sequences with the labels.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5af12e",
   "metadata": {},
   "source": [
    "We create chunks of characters of length 40 from the text with the following character after the chunk used as label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f63a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "text_chunks = [text_encoded[i:i + chunk_size] for i in range(len(text_encoded) - chunk_size + 1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6c94cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 36, 33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47,\n",
       "       40, 29, 42, 32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1,\n",
       "       41, 53, 47, 48, 33, 46, 37])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13dd145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48 36 33  1 41 53 47 48 33 46 37 43 49 47  1 37 47 40 29 42 32  1 10 10\n",
      " 10  0  0  0  0  0 48 36 33  1 41 53 47 48 33 46]  ->  37\n",
      "'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'  ->  'I'\n"
     ]
    }
   ],
   "source": [
    "## inspection:\n",
    "for seq in text_chunks[:1]:\n",
    "    input_seq = seq[:seq_length]\n",
    "    target = seq[seq_length] \n",
    "    print(input_seq, ' -> ', target)\n",
    "    print(repr(''.join(char_array[input_seq])), ' -> ', repr(''.join(char_array[target])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29150556",
   "metadata": {},
   "source": [
    "We create a PyTorch dataset from the set of chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c765b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "    \n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e724f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "\n",
      " Input (x): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "Target (y): 'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERIO'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(' Input (x):', repr(''.join(char_array[seq])))\n",
    "    print('Target (y):', repr(''.join(char_array[target])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2aed5d",
   "metadata": {},
   "source": [
    "We create batches from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772be4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b7e37",
   "metadata": {},
   "source": [
    "## Model definition and training \n",
    "We define a model that contains one LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c52ba7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(85, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=85, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim) \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden, cell\n",
    "    \n",
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size) \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb15923",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08864fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.4364\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 500 #10000 \n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    #seq_batch = seq_batch.to(device)\n",
    "    #target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell) \n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59596b7",
   "metadata": {},
   "source": [
    "## Evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d03b6639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "logits = torch.tensor([[1.0, 1.0, 1.0]])\n",
    "\n",
    "print('Probabilities:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    " \n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda4e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
