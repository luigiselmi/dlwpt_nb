{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de079ef1",
   "metadata": {},
   "source": [
    "# Model evaluation and hyperparameters tuning\n",
    "In this notebook we will see how to build [pipelines](https://scikit-learn.org/stable/modules/compose.html#combining-estimators) of data transformers and estimators with Scikit-Learn and how to assess a model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971d5d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.23.1\n",
      "pandas version: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"numpy version: %s\"%np.__version__)\n",
    "print(\"pandas version: %s\"%pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a9a33",
   "metadata": {},
   "source": [
    "## The Breast Cancer Wisconsin Data Set\n",
    "In this notebook we will use the [Breast Cancer Wisconsin](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) data set from the UCI website. The data set contains 569 records of fine needle aspirate (FNA) of a breast mass with 30 features that describe the characteristics of the cell nuclei. The first two columns represent the unique sample ID and the diagnosis (M=malignant, B = benign)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aefcb7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
    "bcw_df = pd.read_csv(url, header=None)\n",
    "bcw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3378bfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3      4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.8  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.9  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.0  1203.0  0.10960  0.15990  0.1974   \n",
       "\n",
       "        9   ...     22     23     24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.6  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.8  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.5  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcw_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6117153",
   "metadata": {},
   "source": [
    "We change the values of the diagnosis: from malignant (M) to 1, and from benign (B) to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4c5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = bcw_df.loc[:, 2:].values\n",
    "y = bcw_df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d1ce5b",
   "metadata": {},
   "source": [
    "### Data partition\n",
    "We split the data set into a training set (80%) and a validation set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866ca6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1caffe",
   "metadata": {},
   "source": [
    "## Scikit-Learn transformers, estimators and pipelines\n",
    "Scikit-Learn provides several transformations such as the StandardScaler to standardize the input data and the PCA for dimensionality reduction. Classifiers and regressors are classes that implement algorithms for classification and regression tasks such as Logistic Regression or Support Vector Machines and are defined collectively as estimators. Transformer objects implement the fit() and transform() methods, estimator objects implement the fit() and prdict() methods. A pipeline with one or more transformers and a final estimator can be build to implement a task. In the example below we have set up a pipeline with two transformers and a final estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2297d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=2),\n",
    "                        LogisticRegression())\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "test_acc = pipe_lr.score(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b218153",
   "metadata": {},
   "source": [
    "## Model performance assessment\n",
    "So far we have assessed a model performance, that is its generalization performance, using a subset of the original data set, the validation set. This is not a strategy that works in the real world because we may change the model hiperparameters to improve its performance and by training and testing using the same validation test it will make the validation test part of the training set and the model less likely to generalize well with data that have not been seen before. There are two common approaches to address this problem: the holdout method and the k-fold cross validation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e14e0b",
   "metadata": {},
   "source": [
    "### The holdout method\n",
    "The holdout method consists of separating the original data set into three parts: the training set, the validation set and a test set. The validation set is used, as we have seen so far, to validate a model after its training. The test set is used after we have completed the tuning of the model and we want to test its generalization performance with that have never been used before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df94ab8",
   "metadata": {},
   "source": [
    "### K-fold cross validation\n",
    "The strategy used with k-folde cross validation is to split the data into k subsets, k-1 subsets are used for training one the remainng subset is used for validation. If we plan to tune our model's hyperparameters in 10 cycles of trainings and validations we can split the data into 10 subsets and use a different subset for validation at each cycle. Once we are done with the fine tuning we can train again the model with the best hyperparameters using the full data set. Scikit-Learn provides several functions for [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html): from [k-fold](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold) discussed above, to [stratified cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold) in which the k subsets are created with the same percentage of data points from each of the classes in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a373dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 01, Class distr.: [256 153], Acc.: 0.935\n",
      "Fold: 02, Class distr.: [256 153], Acc.: 0.935\n",
      "Fold: 03, Class distr.: [256 153], Acc.: 0.957\n",
      "Fold: 04, Class distr.: [256 153], Acc.: 0.957\n",
      "Fold: 05, Class distr.: [256 153], Acc.: 0.935\n",
      "Fold: 06, Class distr.: [257 153], Acc.: 0.956\n",
      "Fold: 07, Class distr.: [257 153], Acc.: 0.978\n",
      "Fold: 08, Class distr.: [257 153], Acc.: 0.933\n",
      "Fold: 09, Class distr.: [257 153], Acc.: 0.956\n",
      "Fold: 10, Class distr.: [257 153], Acc.: 0.956\n",
      "\n",
      "CV accuracy: 0.950 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10).split(X_train, y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "\n",
    "    print(f'Fold: {k + 1:02d}, '\n",
    "          f'Class distr.: {np.bincount(y_train[train])}, '\n",
    "          f'Acc.: {score:.3f}')\n",
    "    \n",
    "mean_acc = np.mean(scores)\n",
    "std_acc = np.std(scores)\n",
    "print(f'\\nCV accuracy: {mean_acc:.3f} +/- {std_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575ab9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
