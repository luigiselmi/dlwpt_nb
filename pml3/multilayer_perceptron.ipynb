{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1d84fe",
   "metadata": {},
   "source": [
    "# Multilayer perceptron\n",
    "In this notebook we will implement a multilayer perceptron (MLP) with only one single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720db89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.23.1\n",
      "pandas version: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"numpy version: %s\"%np.__version__)\n",
    "print(\"pandas version: %s\"%pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f66b16",
   "metadata": {},
   "source": [
    "## The MNIST data set\n",
    "The MNIST data set is a collection of 70000 28x28 pixels images representing the digits from 0 to 9. the data set is composed of a matrix of 70000 rows, one for each image, and 784 columns that represent the pixel values. The labels are represented in an array of 70000 rows and each value represents the class of that image, that is the digit of the corresponding image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4033d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X.values\n",
    "y = y.astype(int).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a6b4f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = ((X / X.max()) - .5) * 2\n",
    "X_std.min(), X_std.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a09793",
   "metadata": {},
   "source": [
    "We plot a sample of the 10 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba8e8f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAAtCAYAAAD7uP8fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWLUlEQVR4nO2de1QU5/nHvzMLglxEBeUQagAtNthQUTHpMZoaUymY5CiiYlXUFDEqMRhR9LQFomCC8RCBYikQArFeikVj9BgSIkZEtHIzkUasZBXkKlC5w+Lu8vz+4LcTEBZY2N3B9P2cM3/sXD8zszPPvO887zscEYHBYDAYjNEGL7YAg8FgMBj9wQIUg8FgMEYlLEAxGAwGY1TCAhSDwWAwRiUsQDEYDAZjVGKgycxWVlZkb2+vI5W+FBQU1BPRJE2XY579wzy1C/PULsP1BPTrWlpaivr6em44yzLP/lF37jUKUPb29sjPz9ee1SBwHFc2nOWYZ/8wT+3CPLXLcD0B/bq6uroOe1nm2T/qzj2r4mMwGDqhvr4ev/jFLzBt2jSxVRhPKSxAMRgMrbNv3z44OztDKpXiN7/5jdg6jKcUvQWo8vJy7Nq1CxKJBLt27UJ5ebm+Ns1gMPREW1sblixZgv3796Ourg4vvvgijhw5IrYW4ylFLwGqsrISs2bNQlRUFDiOQ1RUFGbPnq2PTY+IxMRESCQScByHu3fviq3Ti87OTrS2tuLLL79EUlISFAqF2EoAuqt1ampqcO7cOXAcB4lE0mfYtGkTlEql2KqDUlxcDFtbW9TV1Ynq0dXVhY6ODmH429/+hsjISPj6+qKlpQXbt28Hx3EwMTFBXFycaJ719fXw9/dHRkYGACA5ORlJSUkYO3asaE4/ZR4/foxFixbBzs4OjY2NYuvoBI2SJIZDWVkZFi5ciIaGBnAcBwsLCxgZGaG2thb37t2DnZ0dJBKJrjU0JjMzEzt37gTPd8dwjhtWMozWaWxsRGRkJC5duoQbN24I4ysrKxESEiKaV01NDY4ePYqEhAR0dXXhwYMH4Hm+3+OWkpKCCRMmIDw8HEZGRjpzKikpQUNDA1544YVhLX/jxg28+uqrWrYanKamJiiVSnz33XfIyMhAY2MjEhIS+sxnb2+PwMBAJCUlwcLCAgsWLMCiRYv07quiubkZx44d6+X33HPPiebzU6OlpQUtLS0AAFNTUxQUFODy5cuYOXPmT/YhQGcBSi6Xo6ysDO7u7r2q81xcXHDgwAHMnz8fjo6OSEhIgK+vr640hs3du3chk8nE1hCoq6tDdHQ0oqOj0dHRASKCg4MDLC0tUVBQgPj4eGzduhWTJg0rS3fE7N27t9fNaTAOHz6MLVu26PQFemZmJu7cuTOsAEVEKCkp0XvJuaKiAi4uLmhoaBhwPp7nhdKJr68vJk+eDDMzM9HOf319PTw8PKDqfPrGjRsjyiLTJydOnIBMJkNRURFiYmIAALNmzdJrFlt/VFdXIyYmBqWlpQCAgoICSKVSAEBkZCSKiopARHB0dERXV5eIpt0p7SkpKfjyyy+Rl5cHADh+/DimTJmCr7/+Ghs3bsRw0tZ1FqB2796N2NjYPuOzsrLQ1tYGT09PnDlzBjdv3tSVwrC5ffs23nvvPQDA7NmzkZGRAVNTU1FcZDIZwsPDERcXh6amJmG8s7MzsrKyoFAoYG1tjYcPH6KpqUm0G9Qbb7whBKhnnnkGu3btQldXl1ACzc7OxmeffaZXp5iYGLi5uQ1r2dbWVnzwwQcICAjQ6zG1tLSEtbV1vwHKzc0NlpaWOHPmDIyMjLBw4UK9eQ3GyZMnIZVKsW7dOsTGxsLc3FxspQG5e/cubt++ja+++goff/yxEFhVJf5bt25h9uzZKCwsFM0xJycHH374ofDb2NgYAQEBOHPmDAIDAwF0+/r7+4tagsrJycGqVavw8OFDEBGWL1+O8vJyrFu3DkD3w15dXd3w3kUS0ZCHOXPm0FB48OABWVpaEs/zxPM8eXl50YkTJ4jnebKzs6PKykrKy8sjALRt2za16wGQr4mfpp79UVJSQnZ2dmRgYEAGBgZ06dKlQZfRpefFixdJIpH0GpydnampqYmIiOrr64XxJSUlonkqlUpqamqipqYmamlp6TNdJpORg4OD4Orn50dyuVynntOnT6eAgIBB3ftjzZo1xHEcxcfHq51HV8czNzeXgoKC6LPPPhOuoZdffpk6OzuJiKi6upr27t075H3R9XXk7u5OJiYm5OTkRPX19UP20pbnUFxbWlpo2bJl5ODgQA4ODjR+/HiSSCTE8zwtWrSozzUmkUho6tSp/a7r/7elE08VR44cIVNTU+J5nnbt2kWHDh2itrY2IiKqqKggGxsb4nmebGxs1F5HuvZUKpUklUrJwsKCJBIJeXl5UXFxMSkUCurs7KS1a9cKx/jYsWMDrkvdude6dEVFBVlaWgonef369dTZ2Uk3b96kpKQk4SATEfE8T+bm5vTgwQONpLXhqY49e/YIN4UVK1YMaRldeq5bt044lk5OTuTv70+NjY3C9IKCglERoAbj2rVrZG5uLriGhYXp1LOyspJMTU2HHaDc3d2J4zi6d++eTj3VIZPJqKuri/bu3Us8z1NWVtaw9kPXnnl5ecTzPEkkEoqMjBQenPTpOZjr999/T46Ojv0GodraWmpvb6fa2loqLi6madOmCdPWrFnT7/r0EaAOHjxIHMeRo6Njrwe+//73v7RlyxbiOI7MzMzo7Nmzateha8+eD89r1qwhmUwmTLt8+XKvQN/zvt8feglQdXV1tH37diGyz5s3j65fv652ftUfe/v27RpJj9RTHW1tbcTzPBkYGJC1tTUVFxcPaTldejY3N9ORI0dIKpVSa2trn+np6emjPkBlZ2fTihUret0Yev6ZdeGZnJxMHMcNK0C1traSra0tcRw34A1XH8fz4MGDQi1EV1eXxvuiS8+Ojg6KiIgQruNPP/20zzynTp2iiIgIioiI0JnnYK7e3t69/numpqZ0+vRpKi0t7TVfcHBwr4dBdTdVfQSo+/fvk6urK/E8T++++y51dnZSc3MzbdiwgXiep8mTJ9PJkycHXIcuPaOjo4Xzvm/fvj7Xs4uLi3As8/LyBt1fnQcouVxOGzZsIIlEQhMmTKBbt25Re3v7gBe4agdff/11jaRH4qmOhoYGevnll4UAFRcXN+RlxSyZ7N69e9QGqKysLHJ1daWxY8f2ukEsXLiQHj9+rFPPwMBA4jiOkpOTNfYOCAggjuNo5syZ1NHRoVPPwejs7CQvLy/ieZ6Kioo03hddespkMlq+fDkBIJ7ne5U2T5w4QSdPnqTp06cLNRIAqLm5WeueA7kWFRUJVVASiYSmT59OP/zwQ7/zqu5fEomEPvjgA7We+ghQcrlcqM2xs7Oj3NxccnR0FI5lWlraoOvQlWdcXBzxPE9jx46lN998s9e1LJfLKT8/X6iejI2NHdL+qjv3WkuSePDggfCS/F//+hemT58OAE9N+mN2djauXbsGAFi5ciU2btworpAa0tLS0NzcDCICx3EoKCgAALz22muYOnWqaF6NjY04deoUvvjiC2Hc+fPne6WZjx8/HkePHsX8+fNhaGioF68XX3xxSPN1dnaioKAACQkJSE1NBdCdZGFsbKxLvUEZM2YMEhISkJmZiaVLl2LZsmV46aWX4OnpKXrTh9u3b+Pzzz8Hz/OYNm0axo0bB6C7yUNmZiZSUlIAAObm5pg6dSq+++47rFy5EqmpqbCwsNCL44EDB9Da2gqg+xqJiIjokzkqk8mQm5uLc+fOCfMtXbpUL37qMDAwwPjx4wF0d3Lw61//Wrjmg4KCsHjxYlG8ZDIZwsLCwHEcVq9ejU8++USY9ujRI3h7e+Obb74BALz11lvw8/Mb0fa0FqD8/f1BRPD09BSC02Cosry6A6h45OXlYcOGDQC6s9ESExNFvzH1RC6Xo6qqCiEhIcJDQM8MuSlTpiA5OVn4rW+qq6uxcOFCIQVWHW+88QaWLFmiJ6tunmzAWFVVha6uLmRlZeH+/ft4/Pgx/vKXv0CpVMLU1BRubm4wNjaGXC6Hk5OTXl3VMXHiRHz11Vdwd3dHVFQUoqKi8Mknn8DLywtmZmaiOHV2duLevXsAuv9/77zzDiwtLVFfX4+DBw8iOTkZ1tbWWLlyJXbv3o329nY4OTmhtrZWr547duxAVVUVJk2ahJSUlH6P14kTJ7B582YAwNy5c3H8+HHRjmtPfv7zn/cZt27dOgQGBgoPA/pGqVTi4cOHALqbirS1tSEtLQ2pqam4fv06mpubwXEcOI7Dpk2bMGbMmJFtUBvFvsLCQjIxMSGJREL/+Mc/hlSkI/qxii80NFSjYt9wPfujoaFBKDbzPE+BgYFDXlbXngqFgkpLS8ne3p4kEgmZm5uTnZ0dbdmypVe1ha2tLR09epQUCoUonlVVVb2qH3pW6Tw57ubNmwOuS1uewcHBxPM8WVlZ0UsvvSQMPM8Tx3FkaGhIEyZMIHd3dwoPD6esrCxqamoihUJBNjY2ZGhoqBdPTaiqqiJvb2/hWAYHBw9YZaZLz2+//Vb4/6mqw1tbW3tV84eGhpJcLqfq6mpycXERxmnbczDXgSgoKBCqoI2NjQdMOlChjyo+pVJJmzdvJo7jhGH9+vUa7ZsuPDs6OsjW1lbIzutZde/g4CDcq2xtbTVyVXfutSJ97do1kkgkNGXKlH5TjJ9ELpdTZGQk8TxP3t7eQvrsUKWH69kff/7zn4WUcgMDA6qtrR3ysrr0VCgUlJ+fL5z8+Ph4oe68vb2d5s2b1ycj6erVq2pTTnXlqaKxsZESExOprKyMqqurew3h4eGCo74CFBFRSkoKbdy4sc+QkZGhNjvvwoULxHEcOTk56c1TEzo6Ouibb74RbhCrVq0SxTMlJUU4pyo8PDyEcf/5z3+IiEgqlQrjBkuUECNA9bzJXrhwYUjL6CNAbd68uc/D3YYNGzTZNZ153r9/n6ytrYnneXJ2dqYPP/yQampqhFR+iURC4eHhGrnqJUA5OjoOKiKXyykmJkZIP7x165bG0sP1fJKKigp67rnnhODk5+c3pOV07alQKCgyMlK4cHx8fISX9W1tbfTKK68ILyljY2Np06ZNwry///3vqbi4mMrLy6m8vFynnkOlo6NDlAA1HLZu3Uocx9GhQ4dGteeYMWOI53kaM2YM3blzR++eqgdMX19fIuq+lp599lnieV6oRamrqxOSJIZSs6LvAPXRRx/1KuUP9eFUlwGqubmZEhMTieM44nmeXnnlFQoKCiKe52nx4sUa7Z8+AmlP7t69KxzPoSRx9ETdudfqSwsfH58Bp1dWVmLnzp1499138eabb0IqlcLZ2VmbChrh6uqKH374AQDwu9/9rt+eL/RNV1cXoqKiEBQUBHNzc5w+fRoJCQkwNjZGWVkZli1bhitXrsDZ2RmFhYXw9/dHbGwsCgsL8fbbbyM9PR3PP/887O3tRe2XrSditsYfLsuXLxdboQ9VVVWIjY3F2rVrhc6B586dO+R3vtpG9a5Bharvxfz8fEydOhXOzs549tln0djYCE9PT1Ec1aFUKpGfny84nz59GlZWVmJroaCgAG+99RaA7s6q09PT4eHhAQCYOXOmmGqDIpPJhOOpch4x2oiqOTk5xPO82pbXRN1pp6reJXbs2DGiqDpczydRpZQbGBjQlStXhrSMrj0///xzkkgkZGFhQdnZ2dTe3k7ffvstbdmyhczMzIQ6f3Xp+1euXCEfHx/y8fHp06pf28dToVDQzZs3B0wZz8jI6PW+7GkpQUml0lHjWVtbS6GhoUIJRTUYGhrS2rVrRfHsWXUnlUrp3LlzNGHCBGGcqi3kUM73SD0Hc32Sx48f04ULFwTPgICAAZsTPImuSiZ37tyhiRMnEs/zVFhYSHK5nBoaGmjGjBnE87xGTV906TkQqirTwRrmPom6c6+VLD7Vk1RFRQX2798PX19fmJub4/vvv0d8fDyys7NRWlqKadOmYfXq1XjnnXe0sdkRoeorTsWvfvUrEW1+ZNu2bQAAhUKBP/3pT2hqasK///1vYXpcXBx8fX3VZuwtWLAACxYs0LlnSUkJ3nvvPaSmpuLRo0d90sY7OjqQm5uL1atXC2m+JiYmoyo7Uh1EhLKyMlHT9oHu/gDPnz+P/fv39+m0dtGiRYiIiMCcOXNEcTM0NISZmRlaW1vh6OjYJ+XdwsICmzdvhouLiyh+6ujs7MTOnTsRHx8PAEhNTYWXl5foKfsAkJ6ejoaGBnh6emLWrFlQKpW4dOkSHj16BCKCjY2N2IoDUlRUpPV1arWzWKVSif379yMpKQkTJ07sJezh4QF3d3e8/fbb2tzksKisrERaWhp4noeRkRFCQ0NF6wz2Sezt7VFTUwOZTIacnBwA3amlixcvhoeHB8aPHy9aOnlPNm7cKHzu4/Dhw33SXs+fP4+srCzhwl++fDkCAwOfis8vcBwnau/QbW1tQmebT3am7Obmhn379mHu3Lmi3lSnTJmCy5cv48CBAzhz5owwfufOnZgzZw5mzZolWtXjQDQ1NQnBacaMGVixYoXIRj+iqh7jOA5KpRK5ublYuXIlrKyssGfPHtHbZg2GqtmBNtFKgPrlL3+J3/72t7h48SKA7k8GVFZWAgAmT56MrVu3Ijg4WBub0gqtra2Cn729Pfbs2SOy0Y9kZmbi+vXryMnJgY2NDby9vWFsbDwqv5mlIiwsTO20Z555Bj4+Pti3bx8MDHT++TGtcenSJb1/C6qjowM7duzA1atXcefOnV7TlixZgpCQELi4uOitkfNguLi44J///KfYGkOmrq4OH330EYDuGhNVg9LRgqp90eTJk7FixQqh4XB6evpT8YHXF154oVf7TG2glTvGuHHjkJaWhqNHj/aqvgsPD4efnx8sLS21sZn/CVSfURhNn1Loj9TUVMTExAgXfE9mzJiBcePGwc3NDX5+fqO+auJJuqvE9UdpaSnef/99XLx4EWVlZb2mmZiYICwsDNu2bRt5o8f/ccLCwvDXv/4VABAaGqq33iyGiuo1Q3x8PIgIkyZNQkhIiKiJZJpgY2OD559/HsXFxXj48CEcHBxGvE6thTozMzNs27YNCoUCSqUSCoUCe/fuHZXBydbWFq+99prYGk81P/vZz/D+++/j7NmzQvbTH/7wB5w9exbXrl3D1atXERIS8tQFJzHeR5w+fRpJSUlCcJo9ezYOHTqEw4cPo66uDjt27GDBaYTU1NQI31P74x//iHnz5ols1JelS5ciOTkZpqam8PT0RHR0NPz9/UdNiXkoREVFAQCCgoKEEuFIeHrqXLSImZkZzp49K7bGU4+BgQFef/111NTUiK2iNV599VW9v38KDAwUPkDH0A3Hjh3D8ePH4ejoiO3bt4v2Yc+BMDY2xvr167F+/XqxVYbN/PnzsWrVKpw6dQpWVlaIjo4e0cOV+G/bGQwGQ8eoakz+/ve/j8rg9FPByMgIycnJCA4ORmJiYr9fhtYEFqAYDMZPHicnJygUCri6uoqt8pNHlRmtUChgbW09onVxmrwQ5jiuDkDZoDNqDzsi0vhxh3mqhXlqF+apXYblCejdlXlqn35dNQpQDAaDwWDoC1bFx2AwGIxRCQtQDAaDwRiVsADFYDAYjFEJC1AMBoPBGJWwAMVgMBiMUQkLUAwGg8EYlbAAxWAwGIxRCQtQDAaDwRiVsADFYDAYjFHJ/wGXH42WGWCfYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=10, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X_std[y == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db4674",
   "metadata": {},
   "source": [
    "And ten examples of handwritten digit 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1333f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=10, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X_std[y == 7][i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56457935",
   "metadata": {},
   "source": [
    "### Data partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c101689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_std, y, test_size=10000, random_state=123, stratify=y)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=5000, random_state=123, stratify=y_temp)\n",
    "\n",
    "# optional to free up some memory by deleting non-used arrays:\n",
    "del X_temp, y_temp, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9755d0",
   "metadata": {},
   "source": [
    "## The multilayer perceptron model\n",
    "We define a MLP class that implements three functions: an init() function to initialize the matrix that will contain the weights of the hidden layer, a forward() function to compute the digit class from an input image, and a backward() function to compute the derivatives of the cost function that are used to update the weights with the backpropagation algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2960ab7",
   "metadata": {},
   "source": [
    "We implement the activation function (sigmoid) and a function of the one-hot encoding of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ef53314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):                                        \n",
    "    return 1. / (1. + np.exp(-z))\n",
    "\n",
    "\n",
    "def int_to_onehot(y, num_labels):\n",
    "\n",
    "    ary = np.zeros((y.shape[0], num_labels))\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1\n",
    "\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18436669",
   "metadata": {},
   "source": [
    "The functions init(), forward() and backward() definitions are similar to the functions defined in PyTorch for a neural network. The size of the weight matrix that represent the connection between the units of the input layer and the units of the hidden layer is (number of features)x(number of units in the hidden layer), in our case 784x50. The size of the 2nd matrix that connects the output of the hidden layer and the output layer is (number of units in the hidden layer)x(number of classes), in our case 50x10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4db14abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetMLP:\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_classes, random_seed=123):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # hidden\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        \n",
    "        self.weight_h = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_hidden, num_features))\n",
    "        self.bias_h = np.zeros(num_hidden)\n",
    "        \n",
    "        # output\n",
    "        self.weight_out = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_classes, num_hidden))\n",
    "        self.bias_out = np.zeros(num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer\n",
    "        # input dim: [n_examples, n_features] dot [n_hidden, n_features].T\n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        z_h = np.dot(x, self.weight_h.T) + self.bias_h\n",
    "        a_h = sigmoid(z_h)\n",
    "\n",
    "        # Output layer\n",
    "        # input dim: [n_examples, n_hidden] dot [n_classes, n_hidden].T\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        z_out = np.dot(a_h, self.weight_out.T) + self.bias_out\n",
    "        a_out = sigmoid(z_out)\n",
    "        return a_h, a_out\n",
    "\n",
    "    def backward(self, x, a_h, a_out, y):  \n",
    "    \n",
    "        #########################\n",
    "        ### Output layer weights\n",
    "        #########################\n",
    "        \n",
    "        # onehot encoding\n",
    "        y_onehot = int_to_onehot(y, self.num_classes)\n",
    "\n",
    "        # Part 1: dLoss/dOutWeights\n",
    "        ## = dLoss/dOutAct * dOutAct/dOutNet * dOutNet/dOutWeight\n",
    "        ## where DeltaOut = dLoss/dOutAct * dOutAct/dOutNet\n",
    "        ## for convenient re-use\n",
    "        \n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_loss__d_a_out = 2.*(a_out - y_onehot) / y.shape[0]\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_a_out__d_z_out = a_out * (1. - a_out) # sigmoid derivative\n",
    "\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        delta_out = d_loss__d_a_out * d_a_out__d_z_out # \"delta (rule) placeholder\"\n",
    "\n",
    "        # gradient for output weights\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        d_z_out__dw_out = a_h\n",
    "        \n",
    "        # input dim: [n_classes, n_examples] dot [n_examples, n_hidden]\n",
    "        # output dim: [n_classes, n_hidden]\n",
    "        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n",
    "        d_loss__db_out = np.sum(delta_out, axis=0)\n",
    "        \n",
    "\n",
    "        #################################        \n",
    "        # Part 2: dLoss/dHiddenWeights\n",
    "        ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet * dHiddenNet/dWeight\n",
    "        \n",
    "        # [n_classes, n_hidden]\n",
    "        d_z_out__a_h = self.weight_out\n",
    "        \n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        d_loss__a_h = np.dot(delta_out, d_z_out__a_h)\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative\n",
    "        \n",
    "        # [n_examples, n_features]\n",
    "        d_z_h__d_w_h = x\n",
    "        \n",
    "        # output dim: [n_hidden, n_features]\n",
    "        d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h)\n",
    "        d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0)\n",
    "\n",
    "        return (d_loss__dw_out, d_loss__db_out, \n",
    "                d_loss__d_w_h, d_loss__d_b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10576240",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "Once we have defined our model and implemented the functions to define the structure of the network, the forward function and the backpropagation algorithm to update the weights in order to minimize the loss, we can instantiate our neural network model and start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba8b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetMLP(num_features=28*28,\n",
    "                     num_hidden=50,\n",
    "                     num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7805f69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65047a7",
   "metadata": {},
   "source": [
    "### The data loading\n",
    "We define a function that creates the mini batches that will be used as input to the network during the training process. Each batch will be used to update the weights as in the stochastic gradient descent (SGD) algorithm used for the backward propagation. The difference between gradient descent and SGD is that with gradient descent the weight are updated using all the training at every epoch while with SGD the weights are updated using a small subset, called the minibatch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80dde608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_generator(X, y, minibatch_size):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start_idx in range(0, indices.shape[0] - minibatch_size + 1, minibatch_size):\n",
    "        batch_idx = indices[start_idx:start_idx + minibatch_size]\n",
    "        yield X[batch_idx], y[batch_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed21fc",
   "metadata": {},
   "source": [
    "We split the data set into minibatches of 100 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d967e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "minibatch_size = 100\n",
    "\n",
    "# iterate over training epochs\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    # iterate over minibatches\n",
    "    minibatch_gen = minibatch_generator(X_train, y_train, minibatch_size)\n",
    "    \n",
    "    for X_train_mini, y_train_mini in minibatch_gen:\n",
    "        break\n",
    "    break\n",
    "    \n",
    "print(X_train_mini.shape)\n",
    "print(y_train_mini.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9071c0d",
   "metadata": {},
   "source": [
    "### The performance metric\n",
    "We define the performance metric to monitor the training process and update the weights accordingly. The loss fumction is the mean squared error (MSE loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a39640c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(targets, probas, num_labels=10):\n",
    "    onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "    return np.mean((onehot_targets - probas)**2)\n",
    "\n",
    "\n",
    "def accuracy(targets, predicted_labels):\n",
    "    return np.mean(predicted_labels == targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec381a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation MSE: 0.3\n",
      "Initial validation accuracy: 9.4%\n"
     ]
    }
   ],
   "source": [
    "_, probas = model.forward(X_valid)\n",
    "mse = mse_loss(y_valid, probas)\n",
    "\n",
    "predicted_labels = np.argmax(probas, axis=1)\n",
    "acc = accuracy(y_valid, predicted_labels)\n",
    "\n",
    "print(f'Initial validation MSE: {mse:.1f}')\n",
    "print(f'Initial validation accuracy: {acc*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef43e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_and_acc(nnet, X, y, num_labels=10, minibatch_size=100):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "    minibatch_gen = minibatch_generator(X, y, minibatch_size)\n",
    "        \n",
    "    for i, (features, targets) in enumerate(minibatch_gen):\n",
    "\n",
    "        _, probas = nnet.forward(features)\n",
    "        predicted_labels = np.argmax(probas, axis=1)\n",
    "        \n",
    "        onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "        loss = np.mean((onehot_targets - probas)**2)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "        \n",
    "        num_examples += targets.shape[0]\n",
    "        mse += loss\n",
    "\n",
    "    mse = mse/i\n",
    "    acc = correct_pred/num_examples\n",
    "    return mse, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d49f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
