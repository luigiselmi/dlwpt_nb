{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097929e9",
   "metadata": {},
   "source": [
    "# Build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330eb602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luigi\\Anaconda3\\envs\\wekeo\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bca16f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bfa04",
   "metadata": {},
   "source": [
    "We define our model as a subclass of nn.Module by implementing the methods init() and forward(). Our model has three layers: two hidden layers with a ReLU activation function and a linear output layer. The output of one layer is the input of the following one. The first layer accepts as input a tensor of size 28x28 float numbers, that can be an image of 28x28 pixels, and the output is a tensor of size 512. The 2nd layer has input size 512 and same output size. The final layer has an input of size 512 and output 10. This layer provided the probabilistic interpretation of the model that maps an image to a set of 10 prbabability values each associated to one of the classes of the FashionMNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ee733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29be7575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd497f1b",
   "metadata": {},
   "source": [
    "The model can be called passing as input a tensor that represents a batch of images. In this case the batch contains only one tensor of 28x28 random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c4b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([7])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "X = torch.rand(batch_size, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560765c4",
   "metadata": {},
   "source": [
    "We try with a minibatch of 3 28x28 tensors of random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d983ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.rand(3,28,28)\n",
    "print(input_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de5617",
   "metadata": {},
   "source": [
    "We can see what a tensor of random values looks like by transforming it into an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61189b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b4ee237760>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "img = to_pil_image(input_tensor)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e9f4d",
   "metadata": {},
   "source": [
    "### Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7825cec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_tensor)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2852cb",
   "metadata": {},
   "source": [
    "### Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718f5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec7f1a",
   "metadata": {},
   "source": [
    "### Non-linear activation ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064df656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.0491,  0.0229, -0.0251,  0.0440, -0.5135,  0.2814,  0.1575, -0.1150,\n",
      "         -0.3286, -0.1887, -0.2296, -0.5831, -0.3966, -0.0027, -0.4715, -0.0915,\n",
      "         -0.3761,  0.0578, -0.2238, -0.2766],\n",
      "        [ 0.1435, -0.4425, -0.1570, -0.3035, -0.1567,  0.6458,  0.1894, -0.1225,\n",
      "         -0.3606,  0.0027, -0.1388, -0.5248, -0.3707,  0.1288, -0.1717, -0.1613,\n",
      "          0.1815,  0.0298, -0.2147, -0.1304],\n",
      "        [ 0.1943, -0.4423,  0.1770, -0.0952,  0.0448,  0.2304,  0.2188,  0.0604,\n",
      "          0.0626,  0.0556, -0.3486, -0.6757, -0.5735, -0.0848, -0.2228,  0.1515,\n",
      "          0.0841, -0.4212, -0.1072, -0.0018]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0229, 0.0000, 0.0440, 0.0000, 0.2814, 0.1575, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0578,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1435, 0.0000, 0.0000, 0.0000, 0.0000, 0.6458, 0.1894, 0.0000, 0.0000,\n",
      "         0.0027, 0.0000, 0.0000, 0.0000, 0.1288, 0.0000, 0.0000, 0.1815, 0.0298,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1943, 0.0000, 0.1770, 0.0000, 0.0448, 0.2304, 0.2188, 0.0604, 0.0626,\n",
      "         0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1515, 0.0841, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eea66f",
   "metadata": {},
   "source": [
    "### Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15ae1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec4f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c8c72ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0214, -0.0050,  0.0152,  ..., -0.0286,  0.0302,  0.0049],\n",
      "        [-0.0105,  0.0027,  0.0233,  ..., -0.0265,  0.0156,  0.0278]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0221,  0.0352], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0390, -0.0266, -0.0012,  ..., -0.0101, -0.0162, -0.0180],\n",
      "        [-0.0243, -0.0135, -0.0194,  ..., -0.0258, -0.0035,  0.0384]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0159,  0.0100], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0176, -0.0376, -0.0187,  ...,  0.0035, -0.0411, -0.0038],\n",
      "        [ 0.0061, -0.0206,  0.0272,  ..., -0.0250, -0.0324,  0.0014]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0055,  0.0122], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1372ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
